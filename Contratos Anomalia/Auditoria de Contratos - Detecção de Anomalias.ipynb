{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01daf7ca-41b3-4a58-b4ad-55b0f99f1a85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Detecção de Anomalias em Contratos\n",
    "\n",
    "O objetivo desta demonstração é desenvolver um processo para identificar anomalias em ordens compras.\n",
    "\n",
    "Para isso, precisamos:\n",
    "- Preparar uma série de variáveis sobre essas compras\n",
    "- Armazená-las de forma a promover seu reaproveitamento\n",
    "- Treinar diversos modelos de ML\n",
    "- Operacionalizar e gerenciá-los em produção\n",
    "\n",
    "<br><img src='https://www.databricks.com/sites/default/files/inline-images/db-392-blog-img-2.png?v=1669127716' width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b8dad45-eef6-4888-ac3d-dabb18921dfc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Conjunto de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec02731-f41a-4df4-8997-9360caec3f42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql USE vr_demo.auditoria_anomalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8dd063a-9132-48a7-b317-42f322b31641",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  dbutils.data.summarize(spark.sql(r\"\"\"SELECT * FROM purchase_orders \"\"\"))\nelse:\n  print(\"This DBR version does not support data profiles.\")\n",
       "commandTitle": "Data Profile",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1729119941065,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "5f9728a0-6cde-4145-97a1-4f8dd924e16a",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 3.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1729119926121,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1729119926044,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": null,
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql SELECT * FROM purchase_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcdad5b5-58ba-4cb0-835e-bdda923b3a12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c51d60fe-6a49-4831-a2b1-608f7ff79515",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Criação das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e7a8a30-6d34-42e3-96cc-b182047bab7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "id_col = 'key_id'\n",
    "num_cols = ['QUANTITY', 'UNIT_PRICE', 'PO_Amount', 'QUANTITY_BILLED', 'QUANTITY_CANCELLED', 'QUANTITY_DELIVERED', 'QUANTITY_ORDERED', 'QuantityDifference', 'POCreationTimeDiff', 'POCreationDayDiff', 'PODistinctCount', 'PotentialSplitPO', 'TotalPSG', 'PSGSpend_Percent', 'CurrentYearSpend', 'PriorYearSpend']\n",
    "cat_cols = ['QuantityVariance', 'BillingVariance']\n",
    "\n",
    "po_df = spark.table('purchase_orders').select(id_col, *num_cols, *cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4976b24a-0bdd-4dd0-8e43-90cdf41f5e3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Registra variáveis no Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "998f5e01-8267-471d-9d53-2e71a41a762d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f6249bb-88c1-4022-9f1e-5c484a380d0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe.create_table(\n",
    "  name=f\"po_features\",\n",
    "  primary_keys=[id_col], \n",
    "  df=po_df, \n",
    "  description=\"Purchase order features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b9052ee-6f58-4d8b-b0ea-cc3b287917a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Recupera variáveis do Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "534bce00-0a18-418f-9d40-e384c608273d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering.entities.feature_lookup import FeatureLookup\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Grab all useful features from different feature store tables\n",
    "feature_lookups = [\n",
    "  FeatureLookup(\n",
    "      table_name=\"po_features\", \n",
    "      lookup_key=\"key_id\"\n",
    "  )\n",
    "]\n",
    "\n",
    "# List desired ids to train on\n",
    "lookup_df = spark.table(\"po_features\").select(\"key_id\").distinct().withColumn('pred_anomalia', lit(0))\n",
    "\n",
    "# Create the training set\n",
    "training_set = fe.create_training_set(\n",
    "    df=lookup_df,\n",
    "    feature_lookups=feature_lookups,\n",
    "    exclude_columns=[id_col],\n",
    "    label='pred_anomalia'\n",
    ")\n",
    "\n",
    "# Load the training data\n",
    "df = training_set.load_df()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b91e2d99-7aca-4966-8b9a-3338d656c53b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Separação das bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0da5262-8c24-413f-977b-37eb6a92c06f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split train and test datasets\n",
    "X_train_raw, X_test_raw = train_test_split(df.drop('pred_anomalia').toPandas(), train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "446244d9-1b90-4c37-8d6c-2ad4208dc45c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e39a4941-af6e-4b91-8a3f-bdaa0dfc426b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# Handling numerical data\n",
    "num = Pipeline(steps=[\n",
    "    ('std', StandardScaler()),\n",
    "    ('imp', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Handling categorical data\n",
    "cat = Pipeline(steps=[\n",
    "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Preprocessor\n",
    "pre = Pipeline(steps=[(\n",
    "  'preprocessor', ColumnTransformer(transformers=[\n",
    "    ('num', num, num_cols),\n",
    "    ('cat', cat, cat_cols)\n",
    "  ])\n",
    ")])\n",
    "\n",
    "# Transform data\n",
    "X_train = pre.fit_transform(X_train_raw)\n",
    "X_test = pre.transform(X_test_raw)\n",
    "\n",
    "# Broadcast data\n",
    "X_train_broadcast = sc.broadcast(X_train)\n",
    "X_test_broadcast = sc.broadcast(X_test)\n",
    "\n",
    "display(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a527fab6-89bb-4524-bf1e-5861613d4c05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Treinamento\n",
    "\n",
    "Para treinarmos nossos modelos mais facilmente, iremos utilizar a biblioteca **`Kakapo`**!\n",
    "\n",
    "Esta biblioteca integra uma das principais biliotecas de detecção de anomalias, a **`PyOD`**, com o **`MLflow`**, **`Spark`** e **`HyperOpt`**.\n",
    "\n",
    "Dessa forma:\n",
    "- Treinamos os diversos tipos de modelos inclusos na PyOD\n",
    "- Aceleramos o treinamento através da distribuição em nosso cluster\n",
    "- Otimizamos o tuning com técnicas bayesianas e genéticas\n",
    "- Mantemos a rastreabilidade de todos os experimentos \n",
    "\n",
    "<br><img src='https://www.databricks.com/sites/default/files/inline-images/logo-kakap.png?v=1679063191' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd3e0706-6b24-4f65-8bd1-3ff1d619e94d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Define o espaço de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "08c69f82-fffb-4142-8e12-8d62d9901094",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-kakapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87d90fad-ff8f-40ba-9037-e94a8db1eec7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from kakapo import get_default_model_space, get_default_search_space\n",
    "from hyperopt import hp\n",
    "\n",
    "model_space = get_default_model_space()\n",
    "model_space.pop('inne') # removes inne algo to save time\n",
    "\n",
    "search_space = hp.choice('model_type', [i for i in get_default_search_space() if i['type'] != 'inne']) # removes inne algo to save time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3711443d-c23b-4945-aa3a-793321c10446",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Define o experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb3bdff5-206c-4129-bb3c-18301e099e25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from kakapo import train_outlier_detection\n",
    "\n",
    "def train_model(params):\n",
    "  y_test = None\n",
    "  y_exists = False\n",
    "  return train_outlier_detection(params, model_space, X_train_broadcast.value, X_test_broadcast.value, y_test, y_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0283c99a-3f28-4c37-93d8-34ebaddfe197",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Roda o experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a34a18c2-5dd8-4673-898e-88a19707f1ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, SparkTrials\n",
    "import mlflow\n",
    "\n",
    "# perform evaluation\n",
    "with mlflow.start_run(run_name='PyOD-Default') as run:\n",
    "  best_params = fmin(\n",
    "    fn=train_model,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=SparkTrials(parallelism=8), # set to the number of available cores\n",
    "    verbose=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "414f6645-22ef-4792-a1eb-2265976ed046",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Registra o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07e737bf-6dc7-4290-87e6-6a52ce2b1b19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_full_name = 'vr_demo.auditoria_anomalia.od_purchase_orders'\n",
    "\n",
    "# Load the best model\n",
    "# Kakapo generates either AUC (supervised) or EM (unsupervised) scores to evaluate models\n",
    "# In both cases, the best model is the one with the highest score\n",
    "# As HyperOpt can only minimize a loss functions, Kakapo returns negative AUC or EM scores\n",
    "# Thus, we need to sort the loss metric in ascending order to find the lowest score\n",
    "runs = mlflow.search_runs(filter_string=f\"tags.mlflow.parentRunId = '{run.info.run_id}'\", order_by=[\"metrics.loss ASC\"])\n",
    "best_run_id = runs.loc[0,'run_id']\n",
    "model = mlflow.pyfunc.load_model(f\"runs:/{best_run_id}/model\")\n",
    "\n",
    "# Assemble the inference pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "  ('pre', pre),\n",
    "  ('od', model)\n",
    "])\n",
    "\n",
    "# Register the best model\n",
    "with mlflow.start_run(run_name='PyOD Final'):\n",
    "  fe.log_model(\n",
    "    model=model_pipeline,\n",
    "    artifact_path=\"model\",\n",
    "    flavor=mlflow.sklearn,\n",
    "    training_set=training_set,\n",
    "    input_example=X_train_raw.head(10),\n",
    "    registered_model_name=model_full_name,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18cf963a-85be-4fae-a6dd-96bb16d0d56d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Cria e Registra um Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae7c18c3-3c21-453d-b858-b656d3f7335a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_full_name = 'vr_demo.auditoria_anomalia.od_purchase_orders'\n",
    "\n",
    "# Load the best ABOD, ECOD and COPOD models\n",
    "def get_best_model(run, model_type):\n",
    "  runs = mlflow.search_runs(filter_string=f\"tags.mlflow.parentRunId = '{run.info.run_id}' and tags.model_type = '{model_type}'\", order_by=[\"metrics.loss ASC\"])\n",
    "  best_run_id = runs.loc[0,'run_id']\n",
    "  return mlflow.pyfunc.load_model(f\"runs:/{best_run_id}/model\")\n",
    "abod = get_best_model(run, 'abod')\n",
    "ecod = get_best_model(run, 'ecod')\n",
    "copod = get_best_model(run, 'copod')\n",
    "\n",
    "# Assemble the inference pipeline\n",
    "class Ensemble(mlflow.pyfunc.PythonModel):\n",
    "  def __init__(self, pre, abod, ecod, copod):\n",
    "    self.abod = abod\n",
    "    self.ecod = ecod\n",
    "    self.copod = copod\n",
    "    self.pre = pre\n",
    "  \n",
    "  def predict(self, context, model_input):\n",
    "    features = pre.transform(model_input)\n",
    "    preds_abod = self.abod.predict(features)\n",
    "    preds_ecod = self.ecod.predict(features)\n",
    "    preds_copod = self.copod.predict(features)\n",
    "    return (preds_abod + preds_ecod + preds_copod > 1)\n",
    "ens = Ensemble(pre, abod, ecod, copod)\n",
    "\n",
    "# Register the best model\n",
    "with mlflow.start_run(run_name='PyOD Ensemble Final'):\n",
    "  fe.log_model(\n",
    "    model=ens,\n",
    "    artifact_path=\"model\",\n",
    "    flavor=mlflow.pyfunc,\n",
    "    training_set=training_set,\n",
    "    input_example=X_train_raw.head(10),\n",
    "    registered_model_name=model_full_name,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96acbe9c-f4fd-42a0-bd2c-8171058c40a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Promove o modelo para produção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5df24bf-a45d-4d27-8fa5-c170a80985a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "production_alias = \"prod\"\n",
    "\n",
    "# Find latest model version\n",
    "client = mlflow.MlflowClient()\n",
    "model_versions = client.search_model_versions(f\"name='{model_full_name}'\")\n",
    "latest_version = max([int(i.version) for i in model_versions])\n",
    "\n",
    "# Move it in Production\n",
    "client.set_registered_model_alias(model_full_name, production_alias, version=latest_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdcbf656-e07c-46a6-a653-aacb8f74b6cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed7008fd-3a73-454a-b227-6948012e1bca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe.score_batch(model_uri=f\"models:/{model_full_name}@{production_alias}\", df=lookup_df, result_type=\"string\") \\\n",
    "  .write.mode(\"overwrite\").saveAsTable(\"po_scored\")\n",
    "display(spark.table(\"po_scored\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a004a9c6-ebe4-4512-88e7-d4f78866d375",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Próximos passos\n",
    "\n",
    "- Ensemble (supervisionado)\n",
    "- Segmentação\n",
    "- Interpretabilidade"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3819540237301076,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Auditoria de Contratos - Detecção de Anomalias",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
